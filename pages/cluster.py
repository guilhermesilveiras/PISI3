import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import seaborn as sns

# Carregar os dados
data = pd.read_csv('data.csv')

# Selecionando apenas dados num√©ricos
numeric_data = data.select_dtypes(include=['float64', 'int64']).drop(columns=['data_quality'], errors='ignore')

# Exibir texto explicativo
st.write("""
## In√≠cio da Clusteriza√ß√£o com K-Means

Primeiro, √© preciso reduzir a dimensionalidade do nosso dataset, que cont√©m mais de 50 colunas. Para isso, vamos utilizara t√©cnica de redu√ß√£o de dimensionalidade, usada para criar um novo conjunto com Componentes Principais (PCs). Esses componentes s√£o combina√ß√µes lineares das vari√°veis originais que capturam a maior parte da variabilidade dos dados. Em seguida, aplicaremos o m√©todo de K-means para agrupar os pa√≠ses em clusters com base nas suas caracter√≠sticas.
""")

# Preenchendo valores ausentes com a m√©dia
imputer = SimpleImputer(strategy="mean")
numeric_data_imputed = pd.DataFrame(imputer.fit_transform(numeric_data), columns=numeric_data.columns)


# Normalizando os dados
scaler = StandardScaler()
numeric_data_scaled = scaler.fit_transform(numeric_data_imputed)


# Exibir texto explicativo
st.write("""
### Normaliza√ß√£o dos Dados

Os dados s√£o ent√£o normalizados para garantir que todas as vari√°veis contribuam igualmente para a an√°lise.
""")

st.markdown(
    """
    <p style='font-size:12px'>scaler = StandartScaler()
    numeric_data_scaled = scaler.fit.transfor(nueric_data_imputed)</p>
    """, 
    unsafe_allow_html=True
)




# Aplicando PCA
pca = PCA(n_components=2)
pca_components = pca.fit_transform(numeric_data_scaled)

# Criando um DataFrame com as duas primeiras componentes principais
pca_df = pd.DataFrame(pca_components, columns=['PC1', 'PC2'])
pca_df['city'] = data['city']
pca_df['country'] = data['country']

# M√©todo do cotovelo 
distortions = []  # lista para armazenar a in√©rcia
range_clusters = range(1, 11)  # testar de 1 a 10 clusters

for k in range_clusters:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(pca_df[['PC1', 'PC2']])  # usar apenas as primeiras duas componentes principais
    distortions.append(kmeans.inertia_)  # adicionar a in√©rcia do modelo atual

# Exibir texto explicativo
st.write("""
### M√©todo do Cotovelo üí™

Utilizamos o m√©todo do cotovelo para determinar o n√∫mero ideal de clusters. O gr√°fico abaixo mostra a in√©rcia (distortion) para diferentes n√∫meros de clusters.
""")

# plotar o gr√°fico do cotovelo
fig, ax = plt.subplots(figsize=(10, 6), facecolor='none')
ax.plot(range_clusters, distortions, marker='o', linestyle='--', color='b')
ax.set_title('M√©todo do Cotovelo para Escolha do N√∫mero de Clusters', fontsize=14)
ax.set_xlabel('N√∫mero de Clusters', fontsize=12)
ax.set_ylabel('In√©rcia (Distortion)', fontsize=12)
ax.grid(True, linestyle='--', alpha=1)
ax.set_xticks(range_clusters)
ax.set_facecolor('none')
fig.patch.set_alpha(0)

# Exibir o gr√°fico no Streamlit
st.pyplot(fig)

st.write("""
Ap√≥s a an√°lise, √© poss√≠vel perceber que o n√∫mero de clusters ideal para o dataframe √© 2. Vamos visualizar alguns gr√°fico resultado da clusteriza√ß√£o:
""")

# Definir lista de pa√≠ses da Am√©rica do Sul
south_american_countries = [
    'Argentina', 'Bolivia', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Guyana', 
    'Paraguay', 'Peru', 'Suriname', 'Uruguay', 'Venezuela'
]

# Filtrar dados para incluir apenas os pa√≠ses da Am√©rica do Sul
south_american_data = data[data['country'].isin(south_american_countries)]

# Selecionar as colunas relevantes (pre√ßos dos apartamentos e pa√≠s)
selected_data = south_american_data[['country', 'x48', 'x49']]

# Remover as linhas com valores ausentes
selected_data = selected_data.dropna()

# realizar a clusteriza√ß√£o com KMeans (n√∫mero de clusters a ser ajustado)
kmeans = KMeans(n_clusters=2, random_state=42)  # Exemplo com 2 clusters
selected_data['cluster'] = kmeans.fit_predict(selected_data[['x48', 'x49']])

# Contar quantos dados caem em cada cluster por pa√≠s
cluster_count = selected_data.groupby(['country', 'cluster']).size().reset_index(name='count')

# Criar o gr√°fico de dispers√£o
fig, ax = plt.subplots(figsize=(12, 6), facecolor='none')
sns.scatterplot(data=selected_data, x='country', y='x48', hue='cluster', palette='Set1', s=100, marker='o', edgecolor='white', ax=ax)
ax.set_title('Clusteriza√ß√£o de Apartamentos na Am√©rica do Sul (x48 e x49)')
ax.set_xlabel('Pa√≠s')
ax.set_ylabel('Frequ√™ncia')
plt.xticks(rotation=90)

# Tornar o fundo dos eixos transparente
ax.set_facecolor('none')
fig.patch.set_alpha(0)

st.pyplot(fig)

# Exibir a quantidade de dados por cluster para cada pa√≠s
st.write(cluster_count)

# Definir lista de pa√≠ses da Am√©rica do Norte
north_american_countries = ['Canada', 'United States', 'Mexico']

# Filtrar dados para incluir apenas os pa√≠ses da Am√©rica do Norte
north_american_data = data[data['country'].isin(north_american_countries)]

# Selecionar as colunas relevantes (pre√ßos dos apartamentos e pa√≠s)
selected_data = north_american_data[['country', 'x48', 'x49']]

# Remover as linhas com valores ausentes
selected_data = selected_data.dropna()

# Realizar a clusteriza√ß√£o com KMeans (n√∫mero de clusters a ser ajustado)
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)  # Exemplo com 3 clusters
selected_data['cluster'] = kmeans.fit_predict(selected_data[['x48', 'x49']])

# Contar quantos dados caem em cada cluster por pa√≠s
cluster_count = selected_data.groupby(['country', 'cluster']).size().reset_index(name='count')

# Criar o gr√°fico de dispers√£o
fig, ax = plt.subplots(figsize=(12, 6), facecolor='none')
sns.scatterplot(data=selected_data, x='country', y='x48', hue='cluster', palette='Set1', s=100, marker='o', edgecolor='white', ax=ax)
ax.set_title('Clusteriza√ß√£o de Apartamentos na Am√©rica do Norte (x48 e x49)')
ax.set_xlabel('Pa√≠s')
ax.set_ylabel('Pre√ßo de Apartamento no Centro (x48)')
plt.xticks(rotation=90)
ax.set_facecolor('none')
fig.patch.set_alpha(0)

# Exibir o gr√°fico no Streamlit
st.pyplot(fig)

# Exibir a quantidade de dados por cluster para cada pa√≠s
st.write(cluster_count)



# criando o modelo K-means com 2 clusters
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
kmeans.fit(pca_df[['PC1', 'PC2']])

# Adicionando os clusters ao DataFrame
pca_df['Cluster'] = kmeans.labels_

# Plotando os clusters
fig, ax = plt.subplots(figsize=(10, 6))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster', palette='Set1', data=pca_df, s=100, alpha=0.7, edgecolor='black', ax=ax)
ax.set_title('Visualiza√ß√£o dos Clusters com PCA', fontsize=14)
ax.set_xlabel('Componente Principal 1 (PC1)', fontsize=12)
ax.set_ylabel('Componente Principal 2 (PC2)', fontsize=12)
ax.legend(title='Clusters')
ax.grid(True, linestyle='--', alpha=0.7)
ax.set_facecolor('none')
fig.patch.set_alpha(0)

st.pyplot(fig)